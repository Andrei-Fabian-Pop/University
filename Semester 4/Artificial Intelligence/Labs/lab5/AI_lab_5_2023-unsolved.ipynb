{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8210b19",
   "metadata": {},
   "source": [
    "## A.I. Assignment 5\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this lab, you should be able to:\n",
    "* Get more familiar with tensors in pytorch \n",
    "* Create a simple multilayer perceptron model with pytorch\n",
    "* Visualise the parameters\n",
    "\n",
    "\n",
    "### Task\n",
    "\n",
    "Build a fully connected feed forward network that adds two bits. Determine the a propper achitecture for this network (what database you use for this problem? how many layers? how many neurons on each layer? what is the activation function? what is the loss function? etc)\n",
    "\n",
    "Create at least 3 such networks and compare their performance (how accurate they are?, how farst they are trained to get at 1 accuracy?)\n",
    "\n",
    "Display for the best one the weights for each layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e3614e5f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-31T08:41:40.382759Z",
     "end_time": "2023-03-31T08:41:40.453651Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5ee7e7d7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-31T08:41:40.427418Z",
     "end_time": "2023-03-31T08:41:40.453871Z"
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "model1 = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(2, 2)),\n",
    "    ('output', nn.Linear(2, 2))\n",
    "]))\n",
    "\n",
    "model2 = nn.Sequential(OrderedDict([\n",
    "    ('function1', nn.Linear(2, 4)),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('function2', nn.Linear(4, 4)),\n",
    "    ('relu2', nn.ReLU()),\n",
    "    ('function3', nn.Linear(4, 2)),\n",
    "    ('sigmoid1', nn.Sigmoid())\n",
    "]))\n",
    "\n",
    "model3 = nn.Sequential(OrderedDict([\n",
    "    ('function1', nn.Linear(2, 3)),\n",
    "    ('sigmoid1', nn.Sigmoid()),\n",
    "    ('function2', nn.Linear(3, 2)),\n",
    "    ('sigmoid2', nn.Sigmoid())\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "665ae958",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-31T08:41:40.427729Z",
     "end_time": "2023-03-31T08:41:40.454055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (hidden): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (output): Linear(in_features=2, out_features=2, bias=True)\n",
      ")\n",
      "Sequential(\n",
      "  (function1): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (function2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (function3): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (sigmoid1): Sigmoid()\n",
      ")\n",
      "Sequential(\n",
      "  (function1): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (sigmoid1): Sigmoid()\n",
      "  (function2): Linear(in_features=3, out_features=2, bias=True)\n",
      "  (sigmoid2): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model1)\n",
    "print(model2)\n",
    "print(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e26f0d3e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-31T08:41:40.428030Z",
     "end_time": "2023-03-31T08:41:40.454190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "#data_in = torch.tensor( ...\n",
    "data_in = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "\n",
    "print(data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4fb16bbc",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-31T08:41:40.428407Z",
     "end_time": "2023-03-31T08:41:40.454314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# data_target = torch.tensor( ...\n",
    "data_target = torch.tensor([[0, 0], [0, 1], [0, 1], [1, 0]], dtype=torch.float32)\n",
    "\n",
    "print(data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "69d920ed",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-31T08:41:40.428736Z",
     "end_time": "2023-03-31T08:41:40.454405Z"
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "# criterion = \n",
    "# optimizer =\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer1 = torch.optim.SGD(model1.parameters(), lr=0.1)\n",
    "optimizer2 = torch.optim.SGD(model2.parameters(), lr=0.1)\n",
    "optimizer3 = torch.optim.SGD(model3.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cde91f6f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-31T08:41:40.429020Z",
     "end_time": "2023-03-31T08:41:57.815581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1\n",
      "Epoch [100/20000], Loss: 0.1622\n",
      "Epoch [200/20000], Loss: 0.1570\n",
      "Epoch [300/20000], Loss: 0.1564\n",
      "Epoch [400/20000], Loss: 0.1563\n",
      "Epoch [500/20000], Loss: 0.1563\n",
      "Epoch [600/20000], Loss: 0.1563\n",
      "Epoch [700/20000], Loss: 0.1563\n",
      "Epoch [800/20000], Loss: 0.1563\n",
      "Epoch [900/20000], Loss: 0.1563\n",
      "Epoch [1000/20000], Loss: 0.1563\n",
      "Epoch [1100/20000], Loss: 0.1563\n",
      "Epoch [1200/20000], Loss: 0.1563\n",
      "Epoch [1300/20000], Loss: 0.1562\n",
      "Epoch [1400/20000], Loss: 0.1562\n",
      "Epoch [1500/20000], Loss: 0.1562\n",
      "Epoch [1600/20000], Loss: 0.1562\n",
      "Epoch [1700/20000], Loss: 0.1562\n",
      "Epoch [1800/20000], Loss: 0.1562\n",
      "Epoch [1900/20000], Loss: 0.1562\n",
      "Epoch [2000/20000], Loss: 0.1563\n",
      "Epoch [2100/20000], Loss: 0.1562\n",
      "Epoch [2200/20000], Loss: 0.1562\n",
      "Epoch [2300/20000], Loss: 0.1562\n",
      "Epoch [2400/20000], Loss: 0.1562\n",
      "Epoch [2500/20000], Loss: 0.1562\n",
      "Epoch [2600/20000], Loss: 0.1562\n",
      "Epoch [2700/20000], Loss: 0.1562\n",
      "Epoch [2800/20000], Loss: 0.1562\n",
      "Epoch [2900/20000], Loss: 0.1562\n",
      "Epoch [3000/20000], Loss: 0.1562\n",
      "Epoch [3100/20000], Loss: 0.1562\n",
      "Epoch [3200/20000], Loss: 0.1562\n",
      "Epoch [3300/20000], Loss: 0.1562\n",
      "Epoch [3400/20000], Loss: 0.1562\n",
      "Epoch [3500/20000], Loss: 0.1562\n",
      "Epoch [3600/20000], Loss: 0.1562\n",
      "Epoch [3700/20000], Loss: 0.1562\n",
      "Epoch [3800/20000], Loss: 0.1562\n",
      "Epoch [3900/20000], Loss: 0.1562\n",
      "Epoch [4000/20000], Loss: 0.1562\n",
      "Epoch [4100/20000], Loss: 0.1562\n",
      "Epoch [4200/20000], Loss: 0.1562\n",
      "Epoch [4300/20000], Loss: 0.1562\n",
      "Epoch [4400/20000], Loss: 0.1562\n",
      "Epoch [4500/20000], Loss: 0.1562\n",
      "Epoch [4600/20000], Loss: 0.1562\n",
      "Epoch [4700/20000], Loss: 0.1562\n",
      "Epoch [4800/20000], Loss: 0.1562\n",
      "Epoch [4900/20000], Loss: 0.1562\n",
      "Epoch [5000/20000], Loss: 0.1562\n",
      "Epoch [5100/20000], Loss: 0.1562\n",
      "Epoch [5200/20000], Loss: 0.1562\n",
      "Epoch [5300/20000], Loss: 0.1562\n",
      "Epoch [5400/20000], Loss: 0.1562\n",
      "Epoch [5500/20000], Loss: 0.1562\n",
      "Epoch [5600/20000], Loss: 0.1562\n",
      "Epoch [5700/20000], Loss: 0.1562\n",
      "Epoch [5800/20000], Loss: 0.1562\n",
      "Epoch [5900/20000], Loss: 0.1562\n",
      "Epoch [6000/20000], Loss: 0.1562\n",
      "Epoch [6100/20000], Loss: 0.1562\n",
      "Epoch [6200/20000], Loss: 0.1562\n",
      "Epoch [6300/20000], Loss: 0.1562\n",
      "Epoch [6400/20000], Loss: 0.1562\n",
      "Epoch [6500/20000], Loss: 0.1562\n",
      "Epoch [6600/20000], Loss: 0.1562\n",
      "Epoch [6700/20000], Loss: 0.1562\n",
      "Epoch [6800/20000], Loss: 0.1562\n",
      "Epoch [6900/20000], Loss: 0.1562\n",
      "Epoch [7000/20000], Loss: 0.1562\n",
      "Epoch [7100/20000], Loss: 0.1562\n",
      "Epoch [7200/20000], Loss: 0.1562\n",
      "Epoch [7300/20000], Loss: 0.1562\n",
      "Epoch [7400/20000], Loss: 0.1562\n",
      "Epoch [7500/20000], Loss: 0.1562\n",
      "Epoch [7600/20000], Loss: 0.1562\n",
      "Epoch [7700/20000], Loss: 0.1562\n",
      "Epoch [7800/20000], Loss: 0.1562\n",
      "Epoch [7900/20000], Loss: 0.1562\n",
      "Epoch [8000/20000], Loss: 0.1562\n",
      "Epoch [8100/20000], Loss: 0.1562\n",
      "Epoch [8200/20000], Loss: 0.1562\n",
      "Epoch [8300/20000], Loss: 0.1562\n",
      "Epoch [8400/20000], Loss: 0.1562\n",
      "Epoch [8500/20000], Loss: 0.1562\n",
      "Epoch [8600/20000], Loss: 0.1562\n",
      "Epoch [8700/20000], Loss: 0.1562\n",
      "Epoch [8800/20000], Loss: 0.1562\n",
      "Epoch [8900/20000], Loss: 0.1562\n",
      "Epoch [9000/20000], Loss: 0.1562\n",
      "Epoch [9100/20000], Loss: 0.1562\n",
      "Epoch [9200/20000], Loss: 0.1562\n",
      "Epoch [9300/20000], Loss: 0.1562\n",
      "Epoch [9400/20000], Loss: 0.1562\n",
      "Epoch [9500/20000], Loss: 0.1562\n",
      "Epoch [9600/20000], Loss: 0.1562\n",
      "Epoch [9700/20000], Loss: 0.1562\n",
      "Epoch [9800/20000], Loss: 0.1562\n",
      "Epoch [9900/20000], Loss: 0.1562\n",
      "Epoch [10000/20000], Loss: 0.1562\n",
      "Epoch [10100/20000], Loss: 0.1562\n",
      "Epoch [10200/20000], Loss: 0.1562\n",
      "Epoch [10300/20000], Loss: 0.1562\n",
      "Epoch [10400/20000], Loss: 0.1562\n",
      "Epoch [10500/20000], Loss: 0.1562\n",
      "Epoch [10600/20000], Loss: 0.1562\n",
      "Epoch [10700/20000], Loss: 0.1562\n",
      "Epoch [10800/20000], Loss: 0.1562\n",
      "Epoch [10900/20000], Loss: 0.1562\n",
      "Epoch [11000/20000], Loss: 0.1562\n",
      "Epoch [11100/20000], Loss: 0.1562\n",
      "Epoch [11200/20000], Loss: 0.1562\n",
      "Epoch [11300/20000], Loss: 0.1562\n",
      "Epoch [11400/20000], Loss: 0.1562\n",
      "Epoch [11500/20000], Loss: 0.1562\n",
      "Epoch [11600/20000], Loss: 0.1562\n",
      "Epoch [11700/20000], Loss: 0.1562\n",
      "Epoch [11800/20000], Loss: 0.1562\n",
      "Epoch [11900/20000], Loss: 0.1562\n",
      "Epoch [12000/20000], Loss: 0.1562\n",
      "Epoch [12100/20000], Loss: 0.1562\n",
      "Epoch [12200/20000], Loss: 0.1562\n",
      "Epoch [12300/20000], Loss: 0.1562\n",
      "Epoch [12400/20000], Loss: 0.1562\n",
      "Epoch [12500/20000], Loss: 0.1562\n",
      "Epoch [12600/20000], Loss: 0.1562\n",
      "Epoch [12700/20000], Loss: 0.1562\n",
      "Epoch [12800/20000], Loss: 0.1562\n",
      "Epoch [12900/20000], Loss: 0.1562\n",
      "Epoch [13000/20000], Loss: 0.1562\n",
      "Epoch [13100/20000], Loss: 0.1562\n",
      "Epoch [13200/20000], Loss: 0.1562\n",
      "Epoch [13300/20000], Loss: 0.1562\n",
      "Epoch [13400/20000], Loss: 0.1562\n",
      "Epoch [13500/20000], Loss: 0.1562\n",
      "Epoch [13600/20000], Loss: 0.1562\n",
      "Epoch [13700/20000], Loss: 0.1562\n",
      "Epoch [13800/20000], Loss: 0.1562\n",
      "Epoch [13900/20000], Loss: 0.1562\n",
      "Epoch [14000/20000], Loss: 0.1562\n",
      "Epoch [14100/20000], Loss: 0.1562\n",
      "Epoch [14200/20000], Loss: 0.1562\n",
      "Epoch [14300/20000], Loss: 0.1562\n",
      "Epoch [14400/20000], Loss: 0.1562\n",
      "Epoch [14500/20000], Loss: 0.1562\n",
      "Epoch [14600/20000], Loss: 0.1562\n",
      "Epoch [14700/20000], Loss: 0.1562\n",
      "Epoch [14800/20000], Loss: 0.1562\n",
      "Epoch [14900/20000], Loss: 0.1562\n",
      "Epoch [15000/20000], Loss: 0.1562\n",
      "Epoch [15100/20000], Loss: 0.1562\n",
      "Epoch [15200/20000], Loss: 0.1562\n",
      "Epoch [15300/20000], Loss: 0.1562\n",
      "Epoch [15400/20000], Loss: 0.1562\n",
      "Epoch [15500/20000], Loss: 0.1562\n",
      "Epoch [15600/20000], Loss: 0.1562\n",
      "Epoch [15700/20000], Loss: 0.1562\n",
      "Epoch [15800/20000], Loss: 0.1562\n",
      "Epoch [15900/20000], Loss: 0.1562\n",
      "Epoch [16000/20000], Loss: 0.1562\n",
      "Epoch [16100/20000], Loss: 0.1562\n",
      "Epoch [16200/20000], Loss: 0.1562\n",
      "Epoch [16300/20000], Loss: 0.1562\n",
      "Epoch [16400/20000], Loss: 0.1562\n",
      "Epoch [16500/20000], Loss: 0.1562\n",
      "Epoch [16600/20000], Loss: 0.1562\n",
      "Epoch [16700/20000], Loss: 0.1562\n",
      "Epoch [16800/20000], Loss: 0.1562\n",
      "Epoch [16900/20000], Loss: 0.1562\n",
      "Epoch [17000/20000], Loss: 0.1562\n",
      "Epoch [17100/20000], Loss: 0.1562\n",
      "Epoch [17200/20000], Loss: 0.1562\n",
      "Epoch [17300/20000], Loss: 0.1562\n",
      "Epoch [17400/20000], Loss: 0.1562\n",
      "Epoch [17500/20000], Loss: 0.1562\n",
      "Epoch [17600/20000], Loss: 0.1562\n",
      "Epoch [17700/20000], Loss: 0.1562\n",
      "Epoch [17800/20000], Loss: 0.1562\n",
      "Epoch [17900/20000], Loss: 0.1562\n",
      "Epoch [18000/20000], Loss: 0.1562\n",
      "Epoch [18100/20000], Loss: 0.1562\n",
      "Epoch [18200/20000], Loss: 0.1562\n",
      "Epoch [18300/20000], Loss: 0.1562\n",
      "Epoch [18400/20000], Loss: 0.1562\n",
      "Epoch [18500/20000], Loss: 0.1562\n",
      "Epoch [18600/20000], Loss: 0.1562\n",
      "Epoch [18700/20000], Loss: 0.1562\n",
      "Epoch [18800/20000], Loss: 0.1562\n",
      "Epoch [18900/20000], Loss: 0.1562\n",
      "Epoch [19000/20000], Loss: 0.1562\n",
      "Epoch [19100/20000], Loss: 0.1562\n",
      "Epoch [19200/20000], Loss: 0.1562\n",
      "Epoch [19300/20000], Loss: 0.1562\n",
      "Epoch [19400/20000], Loss: 0.1562\n",
      "Epoch [19500/20000], Loss: 0.1562\n",
      "Epoch [19600/20000], Loss: 0.1562\n",
      "Epoch [19700/20000], Loss: 0.1562\n",
      "Epoch [19800/20000], Loss: 0.1562\n",
      "Epoch [19900/20000], Loss: 0.1562\n",
      "Epoch [20000/20000], Loss: 0.1562\n",
      "Model 2\n",
      "Epoch [100/20000], Loss: 0.2257\n",
      "Epoch [200/20000], Loss: 0.2213\n",
      "Epoch [300/20000], Loss: 0.2198\n",
      "Epoch [400/20000], Loss: 0.2193\n",
      "Epoch [500/20000], Loss: 0.2190\n",
      "Epoch [600/20000], Loss: 0.2188\n",
      "Epoch [700/20000], Loss: 0.2186\n",
      "Epoch [800/20000], Loss: 0.2183\n",
      "Epoch [900/20000], Loss: 0.2179\n",
      "Epoch [1000/20000], Loss: 0.2175\n",
      "Epoch [1100/20000], Loss: 0.2168\n",
      "Epoch [1200/20000], Loss: 0.2157\n",
      "Epoch [1300/20000], Loss: 0.2140\n",
      "Epoch [1400/20000], Loss: 0.2114\n",
      "Epoch [1500/20000], Loss: 0.2071\n",
      "Epoch [1600/20000], Loss: 0.2005\n",
      "Epoch [1700/20000], Loss: 0.1914\n",
      "Epoch [1800/20000], Loss: 0.1827\n",
      "Epoch [1900/20000], Loss: 0.1768\n",
      "Epoch [2000/20000], Loss: 0.1728\n",
      "Epoch [2100/20000], Loss: 0.1704\n",
      "Epoch [2200/20000], Loss: 0.1687\n",
      "Epoch [2300/20000], Loss: 0.1676\n",
      "Epoch [2400/20000], Loss: 0.1668\n",
      "Epoch [2500/20000], Loss: 0.1661\n",
      "Epoch [2600/20000], Loss: 0.1655\n",
      "Epoch [2700/20000], Loss: 0.1650\n",
      "Epoch [2800/20000], Loss: 0.1645\n",
      "Epoch [2900/20000], Loss: 0.1640\n",
      "Epoch [3000/20000], Loss: 0.1635\n",
      "Epoch [3100/20000], Loss: 0.1630\n",
      "Epoch [3200/20000], Loss: 0.1624\n",
      "Epoch [3300/20000], Loss: 0.1619\n",
      "Epoch [3400/20000], Loss: 0.1614\n",
      "Epoch [3500/20000], Loss: 0.1609\n",
      "Epoch [3600/20000], Loss: 0.1603\n",
      "Epoch [3700/20000], Loss: 0.1598\n",
      "Epoch [3800/20000], Loss: 0.1594\n",
      "Epoch [3900/20000], Loss: 0.1589\n",
      "Epoch [4000/20000], Loss: 0.1585\n",
      "Epoch [4100/20000], Loss: 0.1581\n",
      "Epoch [4200/20000], Loss: 0.1577\n",
      "Epoch [4300/20000], Loss: 0.1574\n",
      "Epoch [4400/20000], Loss: 0.1571\n",
      "Epoch [4500/20000], Loss: 0.1568\n",
      "Epoch [4600/20000], Loss: 0.1565\n",
      "Epoch [4700/20000], Loss: 0.1563\n",
      "Epoch [4800/20000], Loss: 0.1561\n",
      "Epoch [4900/20000], Loss: 0.1558\n",
      "Epoch [5000/20000], Loss: 0.1557\n",
      "Epoch [5100/20000], Loss: 0.1555\n",
      "Epoch [5200/20000], Loss: 0.1553\n",
      "Epoch [5300/20000], Loss: 0.1551\n",
      "Epoch [5400/20000], Loss: 0.1550\n",
      "Epoch [5500/20000], Loss: 0.1548\n",
      "Epoch [5600/20000], Loss: 0.1547\n",
      "Epoch [5700/20000], Loss: 0.1545\n",
      "Epoch [5800/20000], Loss: 0.1544\n",
      "Epoch [5900/20000], Loss: 0.1543\n",
      "Epoch [6000/20000], Loss: 0.1542\n",
      "Epoch [6100/20000], Loss: 0.1541\n",
      "Epoch [6200/20000], Loss: 0.1540\n",
      "Epoch [6300/20000], Loss: 0.1539\n",
      "Epoch [6400/20000], Loss: 0.1538\n",
      "Epoch [6500/20000], Loss: 0.1537\n",
      "Epoch [6600/20000], Loss: 0.1536\n",
      "Epoch [6700/20000], Loss: 0.1536\n",
      "Epoch [6800/20000], Loss: 0.1534\n",
      "Epoch [6900/20000], Loss: 0.1534\n",
      "Epoch [7000/20000], Loss: 0.1533\n",
      "Epoch [7100/20000], Loss: 0.1532\n",
      "Epoch [7200/20000], Loss: 0.1531\n",
      "Epoch [7300/20000], Loss: 0.1530\n",
      "Epoch [7400/20000], Loss: 0.1530\n",
      "Epoch [7500/20000], Loss: 0.1529\n",
      "Epoch [7600/20000], Loss: 0.1529\n",
      "Epoch [7700/20000], Loss: 0.1528\n",
      "Epoch [7800/20000], Loss: 0.1527\n",
      "Epoch [7900/20000], Loss: 0.1527\n",
      "Epoch [8000/20000], Loss: 0.1526\n",
      "Epoch [8100/20000], Loss: 0.1526\n",
      "Epoch [8200/20000], Loss: 0.1525\n",
      "Epoch [8300/20000], Loss: 0.1524\n",
      "Epoch [8400/20000], Loss: 0.1524\n",
      "Epoch [8500/20000], Loss: 0.1523\n",
      "Epoch [8600/20000], Loss: 0.1522\n",
      "Epoch [8700/20000], Loss: 0.1522\n",
      "Epoch [8800/20000], Loss: 0.1522\n",
      "Epoch [8900/20000], Loss: 0.1521\n",
      "Epoch [9000/20000], Loss: 0.1521\n",
      "Epoch [9100/20000], Loss: 0.1520\n",
      "Epoch [9200/20000], Loss: 0.1519\n",
      "Epoch [9300/20000], Loss: 0.1520\n",
      "Epoch [9400/20000], Loss: 0.1519\n",
      "Epoch [9500/20000], Loss: 0.1518\n",
      "Epoch [9600/20000], Loss: 0.1518\n",
      "Epoch [9700/20000], Loss: 0.1517\n",
      "Epoch [9800/20000], Loss: 0.1517\n",
      "Epoch [9900/20000], Loss: 0.1517\n",
      "Epoch [10000/20000], Loss: 0.1516\n",
      "Epoch [10100/20000], Loss: 0.1516\n",
      "Epoch [10200/20000], Loss: 0.1515\n",
      "Epoch [10300/20000], Loss: 0.1516\n",
      "Epoch [10400/20000], Loss: 0.1515\n",
      "Epoch [10500/20000], Loss: 0.1514\n",
      "Epoch [10600/20000], Loss: 0.1515\n",
      "Epoch [10700/20000], Loss: 0.1514\n",
      "Epoch [10800/20000], Loss: 0.1513\n",
      "Epoch [10900/20000], Loss: 0.1513\n",
      "Epoch [11000/20000], Loss: 0.1513\n",
      "Epoch [11100/20000], Loss: 0.1513\n",
      "Epoch [11200/20000], Loss: 0.1512\n",
      "Epoch [11300/20000], Loss: 0.1512\n",
      "Epoch [11400/20000], Loss: 0.1511\n",
      "Epoch [11500/20000], Loss: 0.1511\n",
      "Epoch [11600/20000], Loss: 0.1511\n",
      "Epoch [11700/20000], Loss: 0.1510\n",
      "Epoch [11800/20000], Loss: 0.1510\n",
      "Epoch [11900/20000], Loss: 0.1510\n",
      "Epoch [12000/20000], Loss: 0.1510\n",
      "Epoch [12100/20000], Loss: 0.1509\n",
      "Epoch [12200/20000], Loss: 0.1509\n",
      "Epoch [12300/20000], Loss: 0.1508\n",
      "Epoch [12400/20000], Loss: 0.1509\n",
      "Epoch [12500/20000], Loss: 0.1508\n",
      "Epoch [12600/20000], Loss: 0.1508\n",
      "Epoch [12700/20000], Loss: 0.1507\n",
      "Epoch [12800/20000], Loss: 0.1508\n",
      "Epoch [12900/20000], Loss: 0.1507\n",
      "Epoch [13000/20000], Loss: 0.1507\n",
      "Epoch [13100/20000], Loss: 0.1507\n",
      "Epoch [13200/20000], Loss: 0.1506\n",
      "Epoch [13300/20000], Loss: 0.1506\n",
      "Epoch [13400/20000], Loss: 0.1506\n",
      "Epoch [13500/20000], Loss: 0.1506\n",
      "Epoch [13600/20000], Loss: 0.1505\n",
      "Epoch [13700/20000], Loss: 0.1505\n",
      "Epoch [13800/20000], Loss: 0.1505\n",
      "Epoch [13900/20000], Loss: 0.1505\n",
      "Epoch [14000/20000], Loss: 0.1505\n",
      "Epoch [14100/20000], Loss: 0.1504\n",
      "Epoch [14200/20000], Loss: 0.1504\n",
      "Epoch [14300/20000], Loss: 0.1504\n",
      "Epoch [14400/20000], Loss: 0.1504\n",
      "Epoch [14500/20000], Loss: 0.1504\n",
      "Epoch [14600/20000], Loss: 0.1504\n",
      "Epoch [14700/20000], Loss: 0.1503\n",
      "Epoch [14800/20000], Loss: 0.1503\n",
      "Epoch [14900/20000], Loss: 0.1503\n",
      "Epoch [15000/20000], Loss: 0.1502\n",
      "Epoch [15100/20000], Loss: 0.1502\n",
      "Epoch [15200/20000], Loss: 0.1503\n",
      "Epoch [15300/20000], Loss: 0.1502\n",
      "Epoch [15400/20000], Loss: 0.1502\n",
      "Epoch [15500/20000], Loss: 0.1501\n",
      "Epoch [15600/20000], Loss: 0.1501\n",
      "Epoch [15700/20000], Loss: 0.1501\n",
      "Epoch [15800/20000], Loss: 0.1502\n",
      "Epoch [15900/20000], Loss: 0.1501\n",
      "Epoch [16000/20000], Loss: 0.1501\n",
      "Epoch [16100/20000], Loss: 0.1500\n",
      "Epoch [16200/20000], Loss: 0.1500\n",
      "Epoch [16300/20000], Loss: 0.1500\n",
      "Epoch [16400/20000], Loss: 0.1500\n",
      "Epoch [16500/20000], Loss: 0.1500\n",
      "Epoch [16600/20000], Loss: 0.1500\n",
      "Epoch [16700/20000], Loss: 0.1500\n",
      "Epoch [16800/20000], Loss: 0.1499\n",
      "Epoch [16900/20000], Loss: 0.1499\n",
      "Epoch [17000/20000], Loss: 0.1499\n",
      "Epoch [17100/20000], Loss: 0.1499\n",
      "Epoch [17200/20000], Loss: 0.1498\n",
      "Epoch [17300/20000], Loss: 0.1499\n",
      "Epoch [17400/20000], Loss: 0.1499\n",
      "Epoch [17500/20000], Loss: 0.1498\n",
      "Epoch [17600/20000], Loss: 0.1498\n",
      "Epoch [17700/20000], Loss: 0.1498\n",
      "Epoch [17800/20000], Loss: 0.1498\n",
      "Epoch [17900/20000], Loss: 0.1498\n",
      "Epoch [18000/20000], Loss: 0.1497\n",
      "Epoch [18100/20000], Loss: 0.1498\n",
      "Epoch [18200/20000], Loss: 0.1498\n",
      "Epoch [18300/20000], Loss: 0.1497\n",
      "Epoch [18400/20000], Loss: 0.1497\n",
      "Epoch [18500/20000], Loss: 0.1497\n",
      "Epoch [18600/20000], Loss: 0.1497\n",
      "Epoch [18700/20000], Loss: 0.1496\n",
      "Epoch [18800/20000], Loss: 0.1496\n",
      "Epoch [18900/20000], Loss: 0.1496\n",
      "Epoch [19000/20000], Loss: 0.1497\n",
      "Epoch [19100/20000], Loss: 0.1496\n",
      "Epoch [19200/20000], Loss: 0.1496\n",
      "Epoch [19300/20000], Loss: 0.1496\n",
      "Epoch [19400/20000], Loss: 0.1496\n",
      "Epoch [19500/20000], Loss: 0.1495\n",
      "Epoch [19600/20000], Loss: 0.1495\n",
      "Epoch [19700/20000], Loss: 0.1495\n",
      "Epoch [19800/20000], Loss: 0.1495\n",
      "Epoch [19900/20000], Loss: 0.1496\n",
      "Epoch [20000/20000], Loss: 0.1495\n",
      "Model 3\n",
      "Epoch [100/20000], Loss: 0.2209\n",
      "Epoch [200/20000], Loss: 0.2184\n",
      "Epoch [300/20000], Loss: 0.2177\n",
      "Epoch [400/20000], Loss: 0.2173\n",
      "Epoch [500/20000], Loss: 0.2168\n",
      "Epoch [600/20000], Loss: 0.2163\n",
      "Epoch [700/20000], Loss: 0.2158\n",
      "Epoch [800/20000], Loss: 0.2152\n",
      "Epoch [900/20000], Loss: 0.2145\n",
      "Epoch [1000/20000], Loss: 0.2137\n",
      "Epoch [1100/20000], Loss: 0.2128\n",
      "Epoch [1200/20000], Loss: 0.2118\n",
      "Epoch [1300/20000], Loss: 0.2107\n",
      "Epoch [1400/20000], Loss: 0.2095\n",
      "Epoch [1500/20000], Loss: 0.2082\n",
      "Epoch [1600/20000], Loss: 0.2067\n",
      "Epoch [1700/20000], Loss: 0.2052\n",
      "Epoch [1800/20000], Loss: 0.2035\n",
      "Epoch [1900/20000], Loss: 0.2017\n",
      "Epoch [2000/20000], Loss: 0.1998\n",
      "Epoch [2100/20000], Loss: 0.1979\n",
      "Epoch [2200/20000], Loss: 0.1959\n",
      "Epoch [2300/20000], Loss: 0.1938\n",
      "Epoch [2400/20000], Loss: 0.1917\n",
      "Epoch [2500/20000], Loss: 0.1895\n",
      "Epoch [2600/20000], Loss: 0.1874\n",
      "Epoch [2700/20000], Loss: 0.1852\n",
      "Epoch [2800/20000], Loss: 0.1830\n",
      "Epoch [2900/20000], Loss: 0.1809\n",
      "Epoch [3000/20000], Loss: 0.1787\n",
      "Epoch [3100/20000], Loss: 0.1766\n",
      "Epoch [3200/20000], Loss: 0.1745\n",
      "Epoch [3300/20000], Loss: 0.1725\n",
      "Epoch [3400/20000], Loss: 0.1704\n",
      "Epoch [3500/20000], Loss: 0.1685\n",
      "Epoch [3600/20000], Loss: 0.1666\n",
      "Epoch [3700/20000], Loss: 0.1647\n",
      "Epoch [3800/20000], Loss: 0.1629\n",
      "Epoch [3900/20000], Loss: 0.1611\n",
      "Epoch [4000/20000], Loss: 0.1594\n",
      "Epoch [4100/20000], Loss: 0.1578\n",
      "Epoch [4200/20000], Loss: 0.1562\n",
      "Epoch [4300/20000], Loss: 0.1547\n",
      "Epoch [4400/20000], Loss: 0.1532\n",
      "Epoch [4500/20000], Loss: 0.1519\n",
      "Epoch [4600/20000], Loss: 0.1505\n",
      "Epoch [4700/20000], Loss: 0.1492\n",
      "Epoch [4800/20000], Loss: 0.1480\n",
      "Epoch [4900/20000], Loss: 0.1469\n",
      "Epoch [5000/20000], Loss: 0.1458\n",
      "Epoch [5100/20000], Loss: 0.1447\n",
      "Epoch [5200/20000], Loss: 0.1437\n",
      "Epoch [5300/20000], Loss: 0.1427\n",
      "Epoch [5400/20000], Loss: 0.1418\n",
      "Epoch [5500/20000], Loss: 0.1409\n",
      "Epoch [5600/20000], Loss: 0.1400\n",
      "Epoch [5700/20000], Loss: 0.1392\n",
      "Epoch [5800/20000], Loss: 0.1384\n",
      "Epoch [5900/20000], Loss: 0.1377\n",
      "Epoch [6000/20000], Loss: 0.1369\n",
      "Epoch [6100/20000], Loss: 0.1362\n",
      "Epoch [6200/20000], Loss: 0.1355\n",
      "Epoch [6300/20000], Loss: 0.1348\n",
      "Epoch [6400/20000], Loss: 0.1341\n",
      "Epoch [6500/20000], Loss: 0.1334\n",
      "Epoch [6600/20000], Loss: 0.1328\n",
      "Epoch [6700/20000], Loss: 0.1321\n",
      "Epoch [6800/20000], Loss: 0.1314\n",
      "Epoch [6900/20000], Loss: 0.1307\n",
      "Epoch [7000/20000], Loss: 0.1301\n",
      "Epoch [7100/20000], Loss: 0.1294\n",
      "Epoch [7200/20000], Loss: 0.1286\n",
      "Epoch [7300/20000], Loss: 0.1279\n",
      "Epoch [7400/20000], Loss: 0.1272\n",
      "Epoch [7500/20000], Loss: 0.1264\n",
      "Epoch [7600/20000], Loss: 0.1256\n",
      "Epoch [7700/20000], Loss: 0.1247\n",
      "Epoch [7800/20000], Loss: 0.1239\n",
      "Epoch [7900/20000], Loss: 0.1230\n",
      "Epoch [8000/20000], Loss: 0.1220\n",
      "Epoch [8100/20000], Loss: 0.1210\n",
      "Epoch [8200/20000], Loss: 0.1199\n",
      "Epoch [8300/20000], Loss: 0.1188\n",
      "Epoch [8400/20000], Loss: 0.1177\n",
      "Epoch [8500/20000], Loss: 0.1165\n",
      "Epoch [8600/20000], Loss: 0.1152\n",
      "Epoch [8700/20000], Loss: 0.1139\n",
      "Epoch [8800/20000], Loss: 0.1125\n",
      "Epoch [8900/20000], Loss: 0.1110\n",
      "Epoch [9000/20000], Loss: 0.1094\n",
      "Epoch [9100/20000], Loss: 0.1078\n",
      "Epoch [9200/20000], Loss: 0.1061\n",
      "Epoch [9300/20000], Loss: 0.1043\n",
      "Epoch [9400/20000], Loss: 0.1024\n",
      "Epoch [9500/20000], Loss: 0.1005\n",
      "Epoch [9600/20000], Loss: 0.0984\n",
      "Epoch [9700/20000], Loss: 0.0963\n",
      "Epoch [9800/20000], Loss: 0.0941\n",
      "Epoch [9900/20000], Loss: 0.0919\n",
      "Epoch [10000/20000], Loss: 0.0896\n",
      "Epoch [10100/20000], Loss: 0.0872\n",
      "Epoch [10200/20000], Loss: 0.0848\n",
      "Epoch [10300/20000], Loss: 0.0823\n",
      "Epoch [10400/20000], Loss: 0.0799\n",
      "Epoch [10500/20000], Loss: 0.0774\n",
      "Epoch [10600/20000], Loss: 0.0749\n",
      "Epoch [10700/20000], Loss: 0.0725\n",
      "Epoch [10800/20000], Loss: 0.0700\n",
      "Epoch [10900/20000], Loss: 0.0676\n",
      "Epoch [11000/20000], Loss: 0.0653\n",
      "Epoch [11100/20000], Loss: 0.0630\n",
      "Epoch [11200/20000], Loss: 0.0607\n",
      "Epoch [11300/20000], Loss: 0.0585\n",
      "Epoch [11400/20000], Loss: 0.0563\n",
      "Epoch [11500/20000], Loss: 0.0543\n",
      "Epoch [11600/20000], Loss: 0.0523\n",
      "Epoch [11700/20000], Loss: 0.0503\n",
      "Epoch [11800/20000], Loss: 0.0484\n",
      "Epoch [11900/20000], Loss: 0.0466\n",
      "Epoch [12000/20000], Loss: 0.0449\n",
      "Epoch [12100/20000], Loss: 0.0432\n",
      "Epoch [12200/20000], Loss: 0.0416\n",
      "Epoch [12300/20000], Loss: 0.0401\n",
      "Epoch [12400/20000], Loss: 0.0387\n",
      "Epoch [12500/20000], Loss: 0.0373\n",
      "Epoch [12600/20000], Loss: 0.0359\n",
      "Epoch [12700/20000], Loss: 0.0346\n",
      "Epoch [12800/20000], Loss: 0.0334\n",
      "Epoch [12900/20000], Loss: 0.0323\n",
      "Epoch [13000/20000], Loss: 0.0311\n",
      "Epoch [13100/20000], Loss: 0.0301\n",
      "Epoch [13200/20000], Loss: 0.0291\n",
      "Epoch [13300/20000], Loss: 0.0281\n",
      "Epoch [13400/20000], Loss: 0.0272\n",
      "Epoch [13500/20000], Loss: 0.0263\n",
      "Epoch [13600/20000], Loss: 0.0255\n",
      "Epoch [13700/20000], Loss: 0.0247\n",
      "Epoch [13800/20000], Loss: 0.0239\n",
      "Epoch [13900/20000], Loss: 0.0232\n",
      "Epoch [14000/20000], Loss: 0.0225\n",
      "Epoch [14100/20000], Loss: 0.0218\n",
      "Epoch [14200/20000], Loss: 0.0212\n",
      "Epoch [14300/20000], Loss: 0.0206\n",
      "Epoch [14400/20000], Loss: 0.0200\n",
      "Epoch [14500/20000], Loss: 0.0194\n",
      "Epoch [14600/20000], Loss: 0.0189\n",
      "Epoch [14700/20000], Loss: 0.0184\n",
      "Epoch [14800/20000], Loss: 0.0179\n",
      "Epoch [14900/20000], Loss: 0.0174\n",
      "Epoch [15000/20000], Loss: 0.0170\n",
      "Epoch [15100/20000], Loss: 0.0165\n",
      "Epoch [15200/20000], Loss: 0.0161\n",
      "Epoch [15300/20000], Loss: 0.0157\n",
      "Epoch [15400/20000], Loss: 0.0153\n",
      "Epoch [15500/20000], Loss: 0.0150\n",
      "Epoch [15600/20000], Loss: 0.0146\n",
      "Epoch [15700/20000], Loss: 0.0143\n",
      "Epoch [15800/20000], Loss: 0.0140\n",
      "Epoch [15900/20000], Loss: 0.0136\n",
      "Epoch [16000/20000], Loss: 0.0133\n",
      "Epoch [16100/20000], Loss: 0.0130\n",
      "Epoch [16200/20000], Loss: 0.0128\n",
      "Epoch [16300/20000], Loss: 0.0125\n",
      "Epoch [16400/20000], Loss: 0.0122\n",
      "Epoch [16500/20000], Loss: 0.0120\n",
      "Epoch [16600/20000], Loss: 0.0117\n",
      "Epoch [16700/20000], Loss: 0.0115\n",
      "Epoch [16800/20000], Loss: 0.0113\n",
      "Epoch [16900/20000], Loss: 0.0110\n",
      "Epoch [17000/20000], Loss: 0.0108\n",
      "Epoch [17100/20000], Loss: 0.0106\n",
      "Epoch [17200/20000], Loss: 0.0104\n",
      "Epoch [17300/20000], Loss: 0.0102\n",
      "Epoch [17400/20000], Loss: 0.0101\n",
      "Epoch [17500/20000], Loss: 0.0099\n",
      "Epoch [17600/20000], Loss: 0.0097\n",
      "Epoch [17700/20000], Loss: 0.0095\n",
      "Epoch [17800/20000], Loss: 0.0094\n",
      "Epoch [17900/20000], Loss: 0.0092\n",
      "Epoch [18000/20000], Loss: 0.0090\n",
      "Epoch [18100/20000], Loss: 0.0089\n",
      "Epoch [18200/20000], Loss: 0.0087\n",
      "Epoch [18300/20000], Loss: 0.0086\n",
      "Epoch [18400/20000], Loss: 0.0085\n",
      "Epoch [18500/20000], Loss: 0.0083\n",
      "Epoch [18600/20000], Loss: 0.0082\n",
      "Epoch [18700/20000], Loss: 0.0081\n",
      "Epoch [18800/20000], Loss: 0.0080\n",
      "Epoch [18900/20000], Loss: 0.0078\n",
      "Epoch [19000/20000], Loss: 0.0077\n",
      "Epoch [19100/20000], Loss: 0.0076\n",
      "Epoch [19200/20000], Loss: 0.0075\n",
      "Epoch [19300/20000], Loss: 0.0074\n",
      "Epoch [19400/20000], Loss: 0.0073\n",
      "Epoch [19500/20000], Loss: 0.0072\n",
      "Epoch [19600/20000], Loss: 0.0071\n",
      "Epoch [19700/20000], Loss: 0.0070\n",
      "Epoch [19800/20000], Loss: 0.0069\n",
      "Epoch [19900/20000], Loss: 0.0068\n",
      "Epoch [20000/20000], Loss: 0.0067\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# Train the model\n",
    "\n",
    "num_epochs = 20000\n",
    "models = {\n",
    "    1: model1,\n",
    "    2: model2,\n",
    "    3: model3,\n",
    "}\n",
    "optimizers = {\n",
    "    1: optimizer1,\n",
    "    2: optimizer2,\n",
    "    3: optimizer3,\n",
    "}\n",
    "for i in range(1,4):\n",
    "    print(\"Model \" + str(i))\n",
    "    for epoch in range(num_epochs):\n",
    "        output = models[i](data_in)\n",
    "\n",
    "        loss = criterion(output, data_target)\n",
    "\n",
    "        optimizers[i].zero_grad()\n",
    "        loss.backward()\n",
    "        optimizers[i].step()\n",
    "\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dff3ec1a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-31T08:41:57.817359Z",
     "end_time": "2023-03-31T08:41:57.859538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# visualize the resuts\n",
    "print(data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c1a7518b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-31T08:41:57.859429Z",
     "end_time": "2023-03-31T08:41:57.859865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 1.]])\n",
      "Execution time: 0:00:00.000725\n",
      "Accuracy: 75.00%\n",
      "\n",
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "Execution time: 0:00:00.000336\n",
      "Accuracy: 75.00%\n",
      "\n",
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n",
      "Execution time: 0:00:00.000283\n",
      "Accuracy: 100.00%\n",
      "\n",
      "Model 3 is the best!\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# print model wights\n",
    "from datetime import datetime\n",
    "\n",
    "accuracies = []\n",
    "models = [model1, model2, model3]\n",
    "for model in models:\n",
    "    model.eval()\n",
    "    start_time = datetime.now()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(data_in)\n",
    "        predicted = (outputs >= 0.5).float()\n",
    "        print(predicted)\n",
    "        accuracy = (predicted == data_target).float().mean()\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    print(\"Execution time: {}\".format(end_time - start_time))\n",
    "    print(\"Accuracy: {:.2f}%\".format(accuracy.item() * 100))\n",
    "    print()\n",
    "\n",
    "# Select the best-performing model\n",
    "best_model = models[accuracies.index(max(accuracies))]\n",
    "\n",
    "print('Model ' + str(accuracies.index(max(accuracies)) + 1) + ' is the best!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-03-31T08:41:57.859653Z",
     "end_time": "2023-03-31T08:41:57.859971Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
